{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "import numpy.polynomial as p\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from datetime import datetime , date, timedelta\n",
    "\n",
    "from fottech_lib.market_data.dmds import DMDSServices \n",
    "from fottech_lib import instrumentservice\n",
    "from fottech_lib.market_data.repo import Repo\n",
    "\n",
    "import project.market_data.repocurves as repoc\n",
    "from project.market_data.repocurves import RepoCurves\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the indices\n",
    "file_path = '../data/universe_indices.npy'\n",
    "universe_indices = np.load(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Universe Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_repo_schedules(universe_indices_ric,business_date):\n",
    "    dictionary = {}\n",
    "    for ric in universe_indices_ric:    \n",
    "        print('############################## Index {} ##############################'.format(ric))\n",
    "        try:\n",
    "            div_paths = 'RepoCurve/official/{}/PARIS/INTRADAY/equity/{}/sophis'.format(business_date,ric)\n",
    "            ds = DMDSServices('prod', 'APAC')\n",
    "            docs = ds.get_documents(div_paths)\n",
    "            d_s = docs['documents']['document'][0].__values__.get('content')\n",
    "            repo_schedule = xmltodict.parse(d_s)\n",
    "            date = repo_schedule['RepoCurve']['@businessDate']\n",
    "            df = pd.DataFrame(repo_schedule['RepoCurve']['repo'])\n",
    "            df['#text'] = df['#text'].astype(str)\n",
    "            df['@term'] = df['@term'].astype(str)\n",
    "\n",
    "            for i in range(df.shape[0]):\n",
    "                f_date = datetime.strptime(date, \"%Y-%m-%d\").date()                \n",
    "                l_date = datetime.strptime(df['@term'][i], \"%Y-%m-%d\").date()\n",
    "                delta = l_date - f_date\n",
    "                if (delta.days >= 0):\n",
    "                    df['@term'][i] = delta.days\n",
    "                else:\n",
    "                    df = df.drop(i, axis = 0)\n",
    "            df = df.reset_index(drop=True)\n",
    "            df = df.get_values()\n",
    "            col1 = df[:,0].tolist() \n",
    "            col2 = df[:,1].tolist() \n",
    "            col = [col1 , col2, date]\n",
    "            dictionary[ric]=col\n",
    "        except:\n",
    "            dictionary[ric]=None\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_dict(dictionary):\n",
    "    file_path = '../output/universe_repo_processed.json'\n",
    "    try:\n",
    "        with open(file_path, 'w') as fp:\n",
    "            json.dump(dictionary, fp)\n",
    "        print('file saved')\n",
    "    except:\n",
    "        print('For some reasons, the file couldnt be saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_indices_ric = []\n",
    "B_to_R = instrumentservice.InstrumentService('prod','APAC')\n",
    "for index in universe_indices:\n",
    "    index_ric = B_to_R.transcode(index, target='reuter', partial_match=False)\n",
    "    if(index_ric != None):\n",
    "        ric = index_ric[1:]\n",
    "        universe_indices_ric.append(ric)\n",
    "dictionary = get_repo_schedules(universe_indices_ric,'latest')\n",
    "save_dict(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now cleaning and preprocessing the universe repo curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data_Universe = '../output/universe_repo_processed.json'\n",
    "\n",
    "path_to_cleaned_data_Universe = '../output/universe_repo_cleaned.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('################## Cleaning dividends for Universe index ##################')\n",
    "\n",
    "new_dict = {}\n",
    "with open(path_to_data_Universe) as json_file:\n",
    "    dictionary = json.load(json_file)\n",
    "\n",
    "for key in list(dictionary.keys()):\n",
    "    if (dictionary[key]!=None):\n",
    "        if np.sum(np.isnan(dictionary[key][0]))==0 and np.sum(np.isnan(list(map(float,dictionary[key][1]))))==0 :\n",
    "            dictionary[key][1] = list(map(float,dictionary[key][1]))\n",
    "            new_dict[key] = dictionary[key]\n",
    "\n",
    "xvals = [90, 180, 365, 730, 1095, 1460, 1825, 2190, 2555, 2920, 3285, 3650, 4015, 4380]\n",
    "for key in new_dict.keys():\n",
    "    x = new_dict[key][0]\n",
    "    y = new_dict[key][1]\n",
    "    yinterp = np.interp(xvals, x, y)\n",
    "    #computing new interpolated values\n",
    "    new_dict[key][0] = xvals\n",
    "    new_dict[key][1] = yinterp.tolist()\n",
    "            \n",
    "with open(path_to_cleaned_data_Universe, 'w') as fp:\n",
    "    json.dump(new_dict, fp)\n",
    "print('file saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
