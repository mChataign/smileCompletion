{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"../..\")\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_cleaned_data_SX5E = 'data/cleaned/SX5E/Repo/repo_schedule_SX5E_from_20130101_to_20190726.json'\n",
    "path_to_cleaned_data_NKY = 'data/cleaned/NKY/Repo/repo_schedule_NKY_from_20130101_to_20190726.json'\n",
    "path_to_cleaned_data_SPX = 'data/cleaned/SPX/Repo/repo_schedule_SPX_from_20130101_to_20190726.json'\n",
    "path_to_cleaned_data_UKX = 'data/cleaned/UKX/Repo/repo_schedule_UKX_from_20130101_to_20190726.json'\n",
    "\n",
    "with open(path_to_cleaned_data_SX5E) as json_file:\n",
    "    dictionary_SX5E = json.load(json_file)\n",
    "with open(path_to_cleaned_data_NKY) as json_file:\n",
    "    dictionary_NKY = json.load(json_file)\n",
    "with open(path_to_cleaned_data_SPX) as json_file:\n",
    "    dictionary_SPX = json.load(json_file)\n",
    "with open(path_to_cleaned_data_UKX) as json_file:\n",
    "    dictionary_UKX = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xvals = [7, 15, 30, 60, 120, 240, 350, 480, 960, 1920, 3840, 4500]\n",
    "input_vector_SX5E = []\n",
    "input_vector_NKY = [] \n",
    "input_vector_SPX = []\n",
    "input_vector_UKX = []\n",
    "\n",
    "for key in dictionary_SX5E.keys():\n",
    "    x = dictionary_SX5E[key][0]\n",
    "    y = dictionary_SX5E[key][1]\n",
    "    yinterp = np.interp(xvals, x, y)\n",
    "    #computing new interpolated values\n",
    "    dictionary_SX5E[key][0] = xvals\n",
    "    dictionary_SX5E[key][1] = yinterp\n",
    "    input_vector_SX5E.append(yinterp.tolist())\n",
    "\n",
    "for key in dictionary_NKY.keys():\n",
    "    x = dictionary_NKY[key][0]\n",
    "    y = dictionary_NKY[key][1]\n",
    "    yinterp = np.interp(xvals, x, y)\n",
    "    #computing new interpolated values\n",
    "    dictionary_NKY[key][0] = xvals\n",
    "    dictionary_NKY[key][1] = yinterp\n",
    "    input_vector_NKY.append(yinterp.tolist())\n",
    "\n",
    "for key in dictionary_SPX.keys():\n",
    "    x = dictionary_SPX[key][0]\n",
    "    y = dictionary_SPX[key][1]\n",
    "    yinterp = np.interp(xvals, x, y)\n",
    "    #computing new interpolated values\n",
    "    dictionary_SPX[key][0] = xvals\n",
    "    dictionary_SPX[key][1] = yinterp\n",
    "    input_vector_SPX.append(yinterp.tolist())\n",
    "\n",
    "for key in dictionary_UKX.keys():\n",
    "    x = dictionary_UKX[key][0]\n",
    "    y = dictionary_UKX[key][1]\n",
    "    yinterp = np.interp(xvals, x, y)\n",
    "    #computing new interpolated values\n",
    "    dictionary_UKX[key][0] = xvals\n",
    "    dictionary_UKX[key][1] = yinterp\n",
    "    input_vector_UKX.append(yinterp.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the input_training_set and input_validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_rate = 0.8\n",
    "stop_NKY = int(len(input_vector_NKY)*training_rate)\n",
    "stop_SPX = int(len(input_vector_SPX)*training_rate)\n",
    "stop_SX5E = int(len(input_vector_SX5E)*training_rate)\n",
    "stop_UKX= int(len(input_vector_UKX)*training_rate)\n",
    "\n",
    "input_training_set_NKY = input_vector_NKY[:stop_NKY]\n",
    "input_validation_set_NKY = input_vector_NKY[stop_NKY:]\n",
    "input_training_set_SPX = input_vector_SPX[:stop_SPX]\n",
    "input_validation_set_SPX = input_vector_SPX[stop_SPX:]\n",
    "input_training_set_SX5E = input_vector_SX5E[:stop_SX5E]\n",
    "input_validation_set_SX5E = input_vector_SX5E[stop_SX5E:]\n",
    "input_training_set_UKX = input_vector_UKX[:stop_UKX]\n",
    "input_validation_set_UKX = input_vector_UKX[stop_UKX:]\n",
    "\n",
    "input_training_set = np.vstack((input_training_set_NKY,input_training_set_SPX,input_training_set_SX5E,input_training_set_UKX))\n",
    "input_validation_set = np.vstack((input_validation_set_NKY,input_validation_set_SPX,input_validation_set_SX5E,input_validation_set_UKX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
