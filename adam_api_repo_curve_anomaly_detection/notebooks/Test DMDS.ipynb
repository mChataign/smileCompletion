{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime , date, timedelta\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "import sys\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xmltodict\n",
    "import numpy.polynomial as p\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from project import config\n",
    "from git_repo.fottech_lib.market_data import dividends\n",
    "from git_repo.fottech_lib.market_data.dividends import Dividends \n",
    "from git_repo.fottech_lib.market_data.dmds import DMDSServices \n",
    "from git_repo.fottech_lib import instrumentservice\n",
    "\n",
    "import project.market_data.dividendscurves as divc\n",
    "from project.market_data.dividendscurves import DividendsCurves\n",
    "\n",
    "dmds_date_format = dividends.dmds_date_format\n",
    "dmds_path_date_format = dividends.dmds_path_date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".STOXX50E\n",
      "SX5E\n"
     ]
    }
   ],
   "source": [
    "B_to_R = instrumentservice.InstrumentService('prod','APAC')\n",
    "print(B_to_R.transcode('EURO STOXX 50', target='reuter', partial_match=False))\n",
    "print(B_to_R.transcode('EURO STOXX 50', target='bloomberg', partial_match=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_forward_prices(index, dates1):\n",
    "    import datetime\n",
    "    try:\n",
    "        fetch = datalib.Fetch()\n",
    "        date_time_obj = datetime.datetime.strptime(dates1[0], '%Y%m%d')\n",
    "        forward_object = fetch.forward(index, date_time_obj, date_time_obj, 1)\n",
    "        forward = float(forward_object.to_pandas_series()[0])\n",
    "        return forward\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def computing_dividends_universe(universe_indices, date):\n",
    "    B_to_R = instrumentservice.InstrumentService('prod','APAC')\n",
    "    dates = []\n",
    "    dates.append(date)\n",
    "    dictionary = {}\n",
    "    for index in universe_indices:\n",
    "        print('################## Processing dividends for index {} ##################'.format(index))\n",
    "        try:\n",
    "            index_ric = B_to_R.transcode(index, target='reuter', partial_match=False)\n",
    "            index_ric_div = index_ric[1:]\n",
    "        except:\n",
    "            index_ric = index\n",
    "            index_ric_div = index\n",
    "        print(index_ric)\n",
    "        print(index_ric_div)\n",
    "        splits_index = range(1, int(len(dates)/10)+1)\n",
    "        dates_batch = np.split(dates, splits_index)\n",
    "        for d in dates_batch:\n",
    "            dates1 = d.tolist()\n",
    "            div_schedules = divc.get_dividends_schedules(index_ric_div,dates1)\n",
    "            forward_prices = []\n",
    "            try:\n",
    "                forward_prices.append(get_forward_prices(index_ric, dates1))\n",
    "            except:\n",
    "                forward_prices.append(np.nan)\n",
    "            initial_year = (int)(dates1[0][:4])\n",
    "            years = range(initial_year, initial_year+12)\n",
    "            (n,m) = (len(dates1),len(years))\n",
    "            tot_div = np.zeros((n,m))\n",
    "            \n",
    "            for index1,year in enumerate(years):\n",
    "                year = str(year)\n",
    "                total_divs = divc.total_div_for_many_days_specific_year_f(div_schedules, forward_prices, index_ric_div, year)\n",
    "                tot_div[:,index1] = total_divs\n",
    "        print(forward_prices)\n",
    "        print(tot_div[0].tolist())\n",
    "        dictionary[index] = tot_div[0].tolist()\n",
    "    #divc.save_dict(dictionary, ric, past, future)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "fetch = datalib.Fetch()\n",
    "date_time_obj = datetime.datetime.strptime('20190710', '%Y%m%d')\n",
    "forward_object = fetch.forward('.FCHI', date_time_obj, date_time_obj, 1)\n",
    "forward = float(forward_object.to_pandas_series()[0])\n",
    "forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## Processing dividends for index CAC 40 ##################\n",
      ".FCHI\n",
      "FCHI\n",
      "number of dates :1\n",
      "getting dividends from DMDS...\n",
      "dividends schedules downloaded\n",
      "time to proceed : 0.30503058433532715 s\n",
      "[5567.467135325456]\n",
      "[173.39842800000002, 187.8983174209653, 191.83542487247007, 191.81633027549518, 188.08094900567463, 190.37494087977058, 195.47185467991252, 195.26109777615167, 196.486638996384, 197.1030347037584, 195.03817249260888, 195.55655935757906]\n",
      "################## Processing dividends for index DAX 30 ##################\n",
      ".GDAXI\n",
      "GDAXI\n",
      "number of dates :1\n",
      "getting dividends from DMDS...\n",
      "dividends schedules downloaded\n",
      "time to proceed : 0.3560357093811035 s\n",
      "[12373.03887536221]\n",
      "[399.876156335993, 404.75256796607255, 391.39262499549227, 378.9178738201767, 369.06791267135713, 360.5569953007586, 356.1878113246601, 350.3557477003694, 344.1779180634353, 338.3776197026282, 332.5694677937557, 326.5991053452271]\n",
      "################## Processing dividends for index FTSE 100 ##################\n",
      ".FTSE\n",
      "FTSE\n",
      "number of dates :1\n",
      "getting dividends from DMDS...\n",
      "dividends schedules downloaded\n",
      "time to proceed : 0.4810481071472168 s\n",
      "[7531.123026209912]\n",
      "[325.200025603325, 320.98725297050385, 309.43462515522515, 309.9229938454815, 301.41396446983583, 294.5278255402998, 298.24444521978376, 286.0782183196031, 278.0947760444391, 263.8727020768232, 265.3404426434013, 258.1580106133049]\n"
     ]
    }
   ],
   "source": [
    "#Loading the indices\n",
    "file_path = 'data/processed/UNIVERSE/universe_indices.npy'\n",
    "universe_indices = np.load(file_path)\n",
    "\n",
    "#Preparing processed data\n",
    "yesterday = date.today() - timedelta(days=1)\n",
    "yesterday = yesterday.strftime('%Y%m%d')\n",
    "dictionnaire = computing_dividends_universe(universe_indices[:3], yesterday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = '../data/processed/UNIVERSE/Dividends_Spots/spot_schedule_universe_on_2019-06-03_V0.json'\n",
    "with open(file_path) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "universe_indices = data['indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'data/processed/UNIVERSE/universe_indices.npy'\n",
    "universe_indices = np.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "universe_indices[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "yesterday = date.today() - timedelta(days=1)\n",
    "yesterday = yesterday.strftime('%Y%m%d')\n",
    "dictionnaire = computing_dividends_universe([universe_indices[-1]], yesterday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'data/processed/UNIVERSE/Dividends_Forwards/universe_indices_forwards_on_{}.json'.format(yesterday)\n",
    "with open(file_path, 'w') as fp:\n",
    "    json.dump(dictionnaire, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaning_data_universe(path_to_processed_data,path_to_cleaned_data):\n",
    "    print('################## Cleaning dividends universe ##################')\n",
    "    \n",
    "    data_cleaned = {}\n",
    "    \n",
    "    with open(path_to_processed_data) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "    for indice in list(data.keys()):\n",
    "        if data[indice] is not None:\n",
    "            if np.sum(np.isnan(data[indice]))==0:\n",
    "                data_cleaned[indice] = data[indice]\n",
    "        \n",
    "    with open(path_to_cleaned_data, 'w') as fp:\n",
    "        json.dump(data_cleaned, fp)\n",
    "    print('file saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_processed_data = 'data/processed/UNIVERSE/Dividends_Forwards/universe_indices_forwards_on_{}.json'.format(yesterday)\n",
    "path_to_cleaned_data = 'data/cleaned/UNIVERSE/Dividends_Forwards/universe_indices_forwards_on_{}.json'.format(yesterday)\n",
    "\n",
    "cleaning_data_universe(path_to_processed_data,path_to_cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path_to_cleaned_data) as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scripts.sqlite_populate as ssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import project.data_preprocessing as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scripts import sqlite_populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'data/processed/UNIVERSE/universe_indices.npy'\n",
    "universe_indices = np.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
